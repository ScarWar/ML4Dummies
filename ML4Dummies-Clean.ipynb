{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML for dummies\n",
    "\n",
    "This notebook will show easy but practical uses of Machine learning for beginers.  \n",
    "The goal is to help poeple who find the subject interesting to have handsdown examples\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "1.  Supervised and Unsupervised (RL?)  \n",
    "    a.  Anomaly detection  \n",
    "2.  Intro to ML  \n",
    "    a.  Loss and optimization  \n",
    "    b.  GD  \n",
    "3.  Regression and classification  \n",
    "    a.  Linear regression  \n",
    "    b.  SVM, logistic, KNN   \n",
    "4.  Clustering  \n",
    "    a.  k-means  \n",
    "5.  NN  \n",
    "    a.  Perceptron  \n",
    "    b.  Sigmoid, ReLU, tanh, etc.  \n",
    "    c.  From Perceptron to a network  \n",
    "    d.  Loss -\\> Derivation -\\> Update  \n",
    "    e.  Dense, Conv, RNN  \n",
    "6.  Summery  \n",
    "    a.  Real world examples  \n",
    "        1) YOLO\n",
    "        2) BERT\n",
    "        3) Deepfake (GANs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm,  linear_model\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklean comes with tens of databsets to learn from\n",
    "# we will use the diabetes data set\n",
    "X, y = datasets.load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes dataset\n",
    "Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of `n = 442` diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "For example `X[0]` has the following values  \n",
    "\n",
    "| Age | Sex | Body mass index | Average blood pressure | S1 | S2 | S3 | S4 | S5 | S6 |  \n",
    "|------|------|------|------|------|------|------|------|------|------|\n",
    "|0.0381|0.0507|0.0617|0.0219|-0.0442|-0.0348|-0.0434|-0.0026|0.0199|-0.0176|\n",
    "\n",
    "While the target `y[0]`\n",
    "\n",
    "| measure of disease progression |\n",
    "|------|\n",
    "| 151.0| \n",
    "\n",
    "An important thing to notice is the data is already normalized. We should alway work with normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we shape our data to be simple and easy to explore\n",
    "# We use the `shape` attribute to understand the data we want to learn from\n",
    "print('The shape of the data is: ',  X.shape)\n",
    "print('The shape of each column is: ', X[:,2].shape)\n",
    "\n",
    "# We can use the reshape the data using slicing and `reshape` method\n",
    "X = X[:,2].reshape(__, 1)\n",
    "\n",
    "# Now we use a great util from sklearn which helps us to split the data randomly\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=____, random_state=42)\n",
    "print('Exmaple for a the data set values: \\n', X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.___(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "______ = model._______(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', model.coef_)\n",
    "\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(______, ______,  color='black')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
    "\n",
    "# Make the axes w/o numbers\n",
    "plt.xticks(())\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "### Iris Dataset\n",
    "This data sets consists of 3 different types of irises: Setosa, Versicolour, and Virginica. The rows being the samples and the columns being: Sepal Length, Sepal Width, Petal Length and Petal Width.\n",
    "\n",
    "For example `X[0]` has the following values  \n",
    "\n",
    "| Sepal Length | Sepal Width | Petal Length | Petal Width |\n",
    "|:------:|:------:|:------:|:------:|\n",
    "|5.1|3.5|1.4|0.2|\n",
    "\n",
    "While the target `y[0]`\n",
    "\n",
    "| irise |\n",
    "|:------:|\n",
    "|0|\n",
    "\n",
    "`0` is the categorical number of _I. setosa_. The full match is\n",
    "\n",
    "| irise | cat. # |\n",
    "|:------|:------:|\n",
    "|_I. setosa_|0|\n",
    "|_I. versicolor_|1|\n",
    "|_I. virginica_|2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util methods for visualizing the data\n",
    "\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "    \"\"\"\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "    \"\"\"\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "def plot_classificaition(model, title, X):\n",
    "    \"\"\"Plot the data and the classificaion contours one over the other \n",
    "    \"\"\"\n",
    "    fig, sub = plt.subplots(1, 1)\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "    clf, title, ax = (model, title, sub)\n",
    "    \n",
    "    X0, X1 = X[:, 0], X[:, 1]\n",
    "    xx, yy = make_meshgrid(X0, X1)\n",
    "    plot_contours(ax, clf, xx, yy,\n",
    "                  cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xlabel('Sepal length')\n",
    "    ax.set_ylabel('Sepal width')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "# Take the first two features. We could avoid this by using a two-dim dataset\n",
    "\n",
    "X = iris.____[:, __]\n",
    "y = iris.______\n",
    "\n",
    "# we create an instance of SVM and fit out data. We do not scale our\n",
    "# data since we want to plot the support vectors\n",
    "model = svm.SVC(kernel='linear')\n",
    "\n",
    "# Train the model\n",
    "model.___(X, _)\n",
    "\n",
    "# title for the plot\n",
    "title = 'SVC'\n",
    "\n",
    "plot_classificaition(model, title, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mmnist Dataset\n",
    "\n",
    "This is a copy of the test set of the UCI ML hand-written digits datasets https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
    "\n",
    "The data set contains images of hand-written digits: 10 classes where each class refers to a digit.\n",
    "\n",
    "Preprocessing programs made available by NIST were used to extract normalized bitmaps of handwritten digits from a preprinted form.\n",
    "\n",
    "Although our small dataset has 1797 examples of size 8 x 8, the original dataset has a training set of 60,000 examples, and a test set of 10,000 examples of size 28 x 28.\n",
    "\n",
    "\n",
    "The data that we are interested in is made of 8x8 images of digits, let's have a look at the first 4 images, stored in the `images` attribute of the dataset. Note that each image must have the same size. For these images, we know which digit they represent: it is given in the `target` of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mnist digits dataset\n",
    "X, y = datasets.load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the data as images we need to reshape it with width and height\n",
    "# In the end the example_images should have (samples, width, height) matrix shape:\n",
    "\n",
    "example_images = X.reshape(-1, _, _)\n",
    "images_and_labels = list(zip(example_images, y))\n",
    "\n",
    "_, axes = plt.subplots(1,4)\n",
    "for ax, (image, label) in zip(axes, images_and_labels[:4]):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import normalization process\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, shuffle=False\n",
    ")\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(______, ______)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now predict the value of the digit on the second half:\n",
    "predicted = _____.predict(______)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to visualize our model\n",
    "# For that we will plot the images, the preidcations and the correct tag\n",
    "images = X[len(X) // 2:].reshape(-1, 8, 8)\n",
    "images_and_predictions = list(zip(images, predicted, y_test))\n",
    "_, axes = plt.subplots(1,4)\n",
    "for ax, (image, prediction, real_value) in zip(axes[:], images_and_predictions[:4]):\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('Prediction: %i' % prediction)\n",
    "    ax.set_xlabel('Ground truth: %i' % real_value)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_clf_vectors(coef):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    scale = np.abs(coef).max()\n",
    "    for i in range(10):\n",
    "        l1_plot = plt.subplot(2, 5, i + 1)\n",
    "        l1_plot.imshow(coef[i].reshape(8, 8), interpolation='nearest',\n",
    "                       cmap=plt.cm.RdBu, vmin=-scale, vmax=scale)\n",
    "        l1_plot.set_xticks(())\n",
    "        l1_plot.set_yticks(())\n",
    "        l1_plot.set_xlabel('Class %i' % i)\n",
    "    plt.suptitle('Classification vector for...')\n",
    "    \n",
    "show_classification_vectors(model.coef_.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[_, __]\n",
    "y = iris.target\n",
    "\n",
    "model = KMeans(n_clusters=_)\n",
    "\n",
    "# We want to use only the first two features\n",
    "model.fit(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(12, 4)\n",
    "grid_spec = fig.add_gridspec(1, 2)\n",
    "\n",
    "# Plot our model\n",
    "ax = fig.add_subplot(grid_spec[0, 0])\n",
    "labels = model.labels_\n",
    "\n",
    "ax.scatter(_______, _______,\n",
    "           c=labels.astype(np.float))\n",
    "\n",
    "ax.set_xlabel('Sepal length')\n",
    "ax.set_ylabel('Sepal width')\n",
    "ax.set_title('3 clusters')\n",
    "ax.dist = 12\n",
    "\n",
    "# Plot the ground truth\n",
    "ax = fig.add_subplot(grid_spec[0, 1])\n",
    "labels = y\n",
    "\n",
    "ax.scatter(_______, _______,\n",
    "           c=labels.astype(np.float))\n",
    "\n",
    "ax.set_xlabel('Sepal length')\n",
    "ax.set_ylabel('Sepal width')\n",
    "ax.set_title('Ground Truth')\n",
    "ax.dist = 12\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
